{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-06-05T12:33:15.26244Z","iopub.status.busy":"2022-06-05T12:33:15.261734Z","iopub.status.idle":"2022-06-05T12:35:25.754792Z","shell.execute_reply":"2022-06-05T12:35:25.753464Z","shell.execute_reply.started":"2022-06-05T12:33:15.262341Z"},"trusted":true},"outputs":[],"source":["# !pip install -q ../input/wheels/pretrainedmodels-0.7.4-py3-none-any.whl\n","# !pip install -q ../input/wheels/efficientnet_pytorch-0.6.3-py3-none-any.whl\n","# !pip install -q ../input/wheels/timm-0.4.12-py3-none-any.whl\n","# !pip install -q ../input/wheels/segmentation_models_pytorch-0.2.1-py3-none-any.whl"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T12:35:25.757692Z","iopub.status.busy":"2022-06-05T12:35:25.757264Z","iopub.status.idle":"2022-06-05T12:35:25.763682Z","shell.execute_reply":"2022-06-05T12:35:25.762516Z","shell.execute_reply.started":"2022-06-05T12:35:25.757654Z"},"trusted":true},"outputs":[],"source":["# !pip -q wheel segmentation_models_pytorch\n","import glob\n","import torch\n","import PIL\n","import torchvision.transforms.functional as F\n","from tqdm import tqdm\n","import torch.nn as nn\n","import segmentation_models_pytorch as smp\n","import torch.utils.data as data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T12:35:25.765639Z","iopub.status.busy":"2022-06-05T12:35:25.765274Z","iopub.status.idle":"2022-06-05T12:35:37.405821Z","shell.execute_reply":"2022-06-05T12:35:37.404269Z","shell.execute_reply.started":"2022-06-05T12:35:25.765604Z"},"trusted":true},"outputs":[],"source":["def get_class_names(df):\n","    labels = df['class']\n","    return labels.unique()\n","\n","def make_test_augmenter(conf):\n","    crop_size = round(conf.image_size*conf.crop_size)\n","    return  A.Compose([\n","        A.CenterCrop(height=crop_size, width=crop_size),\n","        ToTensorV2(transpose_mask=True)\n","    ])\n","\n","def get_id(filename):\n","    # e.g. filename: case123_day20/scans/slice_0001_266_266_1.50_1.50.png\n","    # id: case123_day20_slice_0001\n","    tokens = filename.split('/')\n","    return tokens[-3] + '_' + '_'.join(tokens[-1].split('_')[:2])\n","\n","class VisionDataset(data.Dataset):\n","    def __init__(\n","            self, df, conf, input_dir, imgs_dir,\n","            class_names, transform, is_test=False, subset=100):\n","        self.conf = conf\n","        self.transform = transform\n","        self.is_test = is_test\n","\n","        if subset != 100:\n","            assert subset < 100\n","            # train and validate on subsets\n","            num_rows = df.shape[0]*subset//100\n","            df = df.iloc[:num_rows]\n","\n","        files = df['img_files']\n","        self.files = [os.path.join(input_dir, imgs_dir, f) for f in files]\n","        self.masks = [f.replace('train', 'masks') for f in files]\n","\n","    def resize(self, img, interp):\n","        return  cv2.resize(\n","            img, (self.conf.image_size, self.conf.image_size), interpolation=interp)\n","\n","    def load_slice(self, img_file, diff):\n","        slice_num = os.path.basename(img_file).split('_')[1]\n","        filename = (\n","            img_file.replace(\n","                'slice_' + slice_num,\n","                'slice_' + str(int(slice_num) + diff).zfill(4)))\n","        if os.path.exists(filename):\n","            return cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n","        return None\n","\n","    def __getitem__(self, index):\n","        conf = self.conf\n","        img_file = self.files[index]\n","        mid = conf.in_channels//2\n","        # read 5 slices into one image\n","        imgs = [self.load_slice(img_file, i) for i in range(-mid, mid+1)]\n","        for i in range(mid, conf.in_channels-1):\n","            if imgs[i + 1] is None:\n","                imgs[i + 1] = imgs[i]\n","        for i in range(mid, 0, -1):\n","            if imgs[i - 1] is None:\n","                imgs[i - 1] = imgs[i]\n","\n","        img = np.stack(imgs, axis=2)\n","        img = img.astype(np.float32)\n","        max_val = img.max()\n","        if max_val != 0:\n","            img /= max_val\n","        img = self.resize(img, cv2.INTER_AREA)\n","\n","        if self.is_test:\n","            msk = 0\n","            result = self.transform(image=img)\n","            img = result['image']\n","        else:\n","            # read mask\n","            msk_file = self.masks[index]\n","            msk = cv2.imread(msk_file, cv2.IMREAD_UNCHANGED)\n","            msk = self.resize(msk, cv2.INTER_NEAREST)\n","            msk = msk.astype(np.float32)\n","            result = self.transform(image=img, mask=msk)\n","            img, msk = result['image'], result['mask']\n","        return img, msk\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","class ModelWrapper(nn.Module):\n","\n","    def __init__(self, conf, num_classes):\n","        super().__init__()\n","        if conf.arch == 'FPN':\n","            arch = smp.FPN\n","        elif conf.arch == 'Unet':\n","            arch = smp.Unet\n","        elif conf.arch == 'DeepLabV3':\n","            arch = smp.DeepLabV3\n","        else:\n","            assert 0, f'Unknown architecture {conf.arch}'\n","\n","        weights = 'imagenet' if conf.pretrained else None\n","        self.model = arch(\n","            encoder_name=conf.backbone, encoder_weights=weights, in_channels=conf.in_channels,\n","            classes=num_classes, activation=None)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        return  x\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T12:35:37.409434Z","iopub.status.busy":"2022-06-05T12:35:37.408156Z","iopub.status.idle":"2022-06-05T12:35:37.447904Z","shell.execute_reply":"2022-06-05T12:35:37.446756Z","shell.execute_reply.started":"2022-06-05T12:35:37.409387Z"},"trusted":true},"outputs":[],"source":["\n","def create_test_loader(conf, input_dir, class_names):\n","    test_aug = make_test_augmenter(conf)\n","    test_df = pd.DataFrame()\n","    img_files = []\n","    img_dir = 'test'\n","    subdir = ''\n","    while len(img_files) == 0 and len(subdir) < 10:\n","        img_files = sorted(glob.glob(f'{input_dir}/{img_dir}/{subdir}*.png'))\n","        subdir += '*/'\n","        if len(subdir) > 10:\n","            return None\n","    # delete common prefix from paths\n","    if len(img_files) == 0:\n","        img_dir = 'train'\n","        subdir = ''\n","        while len(img_files) == 0 and len(subdir) < 10:\n","            img_files = sorted(glob.glob(f'{input_dir}/{img_dir}/{subdir}*.png'))\n","            subdir += '*/'\n","            if len(subdir) > 10:\n","                return None      \n","        img_files = img_files[:1000]\n","    img_files = [f.replace(f'{input_dir}/{img_dir}/', '') for f in img_files]\n","\n","    test_df['img_files'] = img_files\n","    test_dataset = VisionDataset(\n","        test_df, conf, input_dir, img_dir,\n","        class_names, test_aug, is_test=True)\n","    print(f'{len(test_dataset)} examples in test set')\n","    loader = data.DataLoader(\n","        test_dataset, batch_size=conf.batch_size, shuffle=False,\n","        num_workers=4, pin_memory=False)\n","    return loader, test_df\n","def create_model(conf, model_dir, num_classes):\n","    path_list=glob.glob(model_dir)\n","    path=path_list[0]\n","    print('path_list',path_list)\n","    assert len(path_list)!=0\n","    checkpoint = torch.load(path, map_location=device)\n","    conf.pretrained = False\n","    model = ModelWrapper(conf, num_classes)\n","    model = model.to(device)\n","    model.load_state_dict(checkpoint['model'])\n","    return model\n","def rle_encode(img):\n","    '''\n","    this function is adapted from\n","    https://www.kaggle.com/code/stainsby/fast-tested-rle/notebook\n","    img: numpy array, 1 - mask, 0 - background\n","    Returns run length as string formated\n","    '''\n","    pixels = img.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n","\n","def get_img_shape(filename):\n","    basename = os.path.basename(filename)\n","    tokens = basename.split('_')\n","    height, width = int(tokens[3]), int(tokens[2])\n","    return (height, width)\n","\n","def pad_mask(conf, mask):\n","    # pad image to conf.image_size\n","    padded = np.zeros((conf.image_size, conf.image_size), dtype=mask.dtype)\n","    dh = conf.image_size - mask.shape[0]\n","    dw = conf.image_size - mask.shape[1]\n","\n","    top = dh//2\n","    left = dw//2\n","    padded[top:top + mask.shape[0], left:left + mask.shape[1]] = mask\n","    return padded\n","\n","def resize_mask(mask, height, width):\n","    return cv2.resize(mask, (width, height), interpolation=cv2.INTER_NEAREST)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["\n","def run(input_dir, model_dir, thresh):\n","    meta_file = os.path.join(input_dir, 'train.csv')\n","    train_df = pd.read_csv(meta_file, dtype=str)\n","    class_names = np.array(get_class_names(train_df))\n","    num_classes = len(class_names)\n","\n","    model = create_model(conf, model_dir, num_classes)\n","    loader, df = create_test_loader(conf, input_dir, class_names)\n","    img_files = df['img_files']\n","\n","    subm = pd.read_csv(f'{input_dir}/sample_submission.csv')\n","    del subm['predicted']\n","\n","    ids = []\n","    classes = []\n","    masks = []\n","    img_idx = 0\n","    sigmoid = nn.Sigmoid()\n","    model.eval()\n","    with torch.no_grad():\n","#         qdar=tqdm(enumerate(loader),le=len())\n","        for images, _ in loader:\n","            images = images.to(device)\n","            outputs = model(images)\n","            preds = sigmoid(outputs).cpu().numpy()\n","            preds[preds >= thresh] = 1\n","            preds[preds < thresh] = 0\n","            for pred in preds:\n","                img_file = img_files[img_idx]\n","                img_idx += 1\n","                img_id = get_id(img_file)\n","                height, width = get_img_shape(img_file)\n","                for class_id, class_name in enumerate(class_names):\n","                    mask = pred[class_id]\n","                    mask = pad_mask(conf, mask)\n","                    mask = resize_mask(mask, height, width)\n","                    enc_mask = '' if mask.sum() == 0 else rle_encode(mask)\n","                    ids.append(img_id)\n","                    classes.append(class_name)\n","                    masks.append(enc_mask)\n","\n","    pred_df = pd.DataFrame({'id': ids, 'class': classes, 'predicted': masks})\n","    if pred_df.shape[0] > 0:\n","        # sort according to the given order and save to a csv file\n","        subm = subm.merge(pred_df, on=['id', 'class'])\n","    subm.to_csv('submission.csv', index=False)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["class Config():\n","    # FPN, Unet or DeepLab\n","    arch = 'Unet'\n","    backbone = 'efficientnet-b3'\n","    pretrained = True\n","    in_channels = 7\n","    # crop to this fraction of image_size\n","    crop_size = 0.9\n","    # resize images to this size on the fly\n","    image_size = 320\n","\n","    # optimizer settings\n","    optim = 'adamw'\n","    lr = 0.001\n","    weight_decay = 0.01\n","    batch_size = 32\n","\n","    # scheduler settings\n","    gamma = 0.96\n","\n","    # data augmentation\n","    aug_prob = 0.4\n","    strong_aug = True\n","    max_cutout = 0\n","\n","    att = True\n","\n","    \n","conf = Config()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# device=torch.device('cpu')"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-06-05T12:35:37.450437Z","iopub.status.busy":"2022-06-05T12:35:37.4493Z","iopub.status.idle":"2022-06-05T12:42:21.450933Z","shell.execute_reply":"2022-06-05T12:42:21.449394Z","shell.execute_reply.started":"2022-06-05T12:35:37.450395Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["path_list ['/home/ray/workspace/Fly_Pluche/kaggle/gi-tract/ckpt/Unet_efficientnet-b3/bestmodel_Unetefficientnet-b3_2.pth']\n","1000 examples in test set\n"]}],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from albumentations.pytorch import ToTensorV2\n","import albumentations as A\n","import cv2\n","\n","test_thresh = 0.45\n","run('/home/ray/workspace/Fly_Pluche/kaggle/origin_net/input/uw-madison-gi-tract-image-segmentation',\n","    '/home/ray/workspace/Fly_Pluche/kaggle/gi-tract/ckpt/Unet_efficientnet-b3/bestmodel_Unetefficientnet-b3_*.pth', test_thresh)\n","print('over')"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"interpreter":{"hash":"669f78cbe26ec9fb0b6eae54fd2fbfb46ec4e51bc69292cf1bdca42e2e82d9fb"},"kernelspec":{"display_name":"Python 3.7.0 ('Fly_Pluche')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":4}
